# ç”¨äºå°†CodeRM-UnitTestæ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶ä¿å­˜ä¸ºjsonlæ ¼å¼
import pandas as pd
import json
import ast
import os
import random
from tqdm import tqdm

# ================= é…ç½®è·¯å¾„ =================
BASE_DIR = "datasets"
SOURCE_DIR = os.path.join(BASE_DIR, "CodeRM-UnitTest")
OUTPUT_DIR = os.path.join(BASE_DIR, "CodeRM-filter")

# è¾“å…¥æ–‡ä»¶è·¯å¾„
FILE_CF = os.path.join(SOURCE_DIR, "unit_test_codefeedback-filter.parquet")
FILE_TACO = os.path.join(SOURCE_DIR, "unit_test_taco-train.parquet")

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ================= è¾…åŠ©å‡½æ•° =================

def get_function_name(code):
    """æå–å…¥å£å‡½æ•°å"""
    try:
        tree = ast.parse(code)
        for node in tree.body:
            if isinstance(node, ast.FunctionDef):
                return node.name
    except:
        return None
    return None

def is_code_clean(code):
    """
    è¿‡æ»¤é€»è¾‘ï¼š
    1. ä»£ç è¡Œæ•° > 60 åˆ™å‰”é™¤ (RLè®¡ç®—æˆæœ¬æ§åˆ¶)
    2. å‰”é™¤å±é™©ä¾èµ– (requests, socketç­‰)
    """
    if len(code.split('\n')) > 60: 
        return False
    
    forbidden_keywords = [
        'import requests', 'import socket', 'import threading', 
        'subprocess', 'open(', 'sys.stdin'
    ]
    if any(k in code for k in forbidden_keywords):
        return False
        
    return True

def process_and_save(source_name, input_path):
    """
    å¤„ç†å•ä¸ªæ•°æ®é›†å¹¶ä¿å­˜ä¸º Train/Test ä¸¤ä¸ªæ–‡ä»¶
    """
    print(f"\nğŸš€ Processing {source_name} from: {input_path}")
    
    if not os.path.exists(input_path):
        print(f"âŒ Error: File not found: {input_path}")
        return

    # 1. è¯»å–æ•°æ®
    df = pd.read_parquet(input_path)
    processed_items = []
    
    # 2. æ¸…æ´—ä¸æå–
    # ä½¿ç”¨å‰ç¼€åŒºåˆ† IDï¼Œä¾‹å¦‚ "cf_0", "taco_0"
    prefix = "cf" if "codefeedback" in source_name.lower() else "taco"
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f"Cleaning {source_name}"):
        code = row['code_ground_truth']
        
        # è¿‡æ»¤
        if not is_code_clean(code):
            continue
            
        entry_point = get_function_name(code)
        if not entry_point:
            continue
            
        # æ„å»ºæ•°æ®
        item = {
            "task_id": f"{prefix}_{row['task_id']}",
            "prompt": code,  # RL è¾“å…¥
            "entry_point": entry_point,
            "canonical_solution": code, # Ground Truth
            "original_question": row.get('question', '')
        }
        processed_items.append(item)

    print(f"ğŸ“Š Stats for {source_name}: Raw {len(df)} -> Valid {len(processed_items)}")

    # 3. æ‰“ä¹±ä¸åˆ‡åˆ†
    random.seed(42)
    random.shuffle(processed_items)

    test_size = 100
    if len(processed_items) > test_size:
        test_data = processed_items[:test_size]
        train_data = processed_items[test_size:]
    else:
        # æå°‘æƒ…å†µåšå…œåº•
        test_data = processed_items
        train_data = []

    # 4. å®šä¹‰è¾“å‡ºæ–‡ä»¶å
    train_file = os.path.join(OUTPUT_DIR, f"mist_train_{prefix}.jsonl")
    test_file = os.path.join(OUTPUT_DIR, f"mist_test_{prefix}.jsonl")

    # 5. å†™å…¥æ–‡ä»¶
    print(f"ğŸ’¾ Saving to {OUTPUT_DIR}...")
    
    with open(train_file, 'w', encoding='utf-8') as f:
        for item in train_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
            
    with open(test_file, 'w', encoding='utf-8') as f:
        for item in test_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"âœ… {source_name} Done:")
    print(f"   - Train: {len(train_data)} samples -> {os.path.basename(train_file)}")
    print(f"   - Test:  {len(test_data)} samples  -> {os.path.basename(test_file)}")

# ================= ä¸»æ‰§è¡Œæµç¨‹ =================

def main():
    # å¤„ç† CodeFeedback
    process_and_save("CodeFeedback", FILE_CF)
    
    # å¤„ç† TACO
    process_and_save("TACO", FILE_TACO)

if __name__ == "__main__":
    main()