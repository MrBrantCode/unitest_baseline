{
  "task_id": "taco_13159",
  "entry_point": "follows_pattern",
  "mutant_count": 19,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "token_p = 0",
      "mutated_line": "token_p = 1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 1\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "token_p = 0",
      "mutated_line": "token_p = -1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = -1\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "token_p = 0",
      "mutated_line": "token_p = 1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 1\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "token_s = 0",
      "mutated_line": "token_s = 1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 1\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "token_s = 0",
      "mutated_line": "token_s = -1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = -1\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "token_s = 0",
      "mutated_line": "token_s = 1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 1\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "ROR",
      "lineno": 22,
      "original_line": "return pattern_tokenize == str_tokenize",
      "mutated_line": "return pattern_tokenize != str_tokenize",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize != str_tokenize"
    },
    {
      "operator": "ROR",
      "lineno": 11,
      "original_line": "if char not in pattern_dict:",
      "mutated_line": "if char in pattern_dict:",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "ASR",
      "lineno": 13,
      "original_line": "token_p += 1",
      "mutated_line": "token_p -= 1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p -= 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "ROR",
      "lineno": 17,
      "original_line": "if word not in str_dict:",
      "mutated_line": "if word in str_dict:",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "ASR",
      "lineno": 19,
      "original_line": "token_s += 1",
      "mutated_line": "token_s -= 1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s -= 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 13,
      "original_line": "token_p += 1",
      "mutated_line": "token_p += 2",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 2\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 13,
      "original_line": "token_p += 1",
      "mutated_line": "token_p += 0",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 0\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 13,
      "original_line": "token_p += 1",
      "mutated_line": "token_p += 0",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 0\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 13,
      "original_line": "token_p += 1",
      "mutated_line": "token_p += -1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += -1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 19,
      "original_line": "token_s += 1",
      "mutated_line": "token_s += 2",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 2\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 19,
      "original_line": "token_s += 1",
      "mutated_line": "token_s += 0",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 0\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 19,
      "original_line": "token_s += 1",
      "mutated_line": "token_s += 0",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += 0\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    },
    {
      "operator": "CRP",
      "lineno": 19,
      "original_line": "token_s += 1",
      "mutated_line": "token_s += -1",
      "code": "def follows_pattern(pattern: str, str: str) -> bool:\n    str_arr = str.split()\n    pattern_dict = {}\n    str_dict = {}\n    pattern_tokenize = []\n    token_p = 0\n    str_tokenize = []\n    token_s = 0\n    for char in pattern:\n        if char not in pattern_dict:\n            pattern_dict[char] = token_p\n            token_p += 1\n        pattern_tokenize.append(pattern_dict[char])\n    for word in str_arr:\n        if word not in str_dict:\n            str_dict[word] = token_s\n            token_s += -1\n        str_tokenize.append(str_dict[word])\n    return pattern_tokenize == str_tokenize"
    }
  ]
}