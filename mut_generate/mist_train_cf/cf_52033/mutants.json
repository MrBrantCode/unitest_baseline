{
  "task_id": "cf_52033",
  "entry_point": "naive_bayes_multiclass",
  "mutant_count": 25,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 3,
      "original_line": "def naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):",
      "mutated_line": "def naive_bayes_multiclass(train_data, train_labels, test_instance, k=2):",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=2):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "CRP",
      "lineno": 3,
      "original_line": "def naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):",
      "mutated_line": "def naive_bayes_multiclass(train_data, train_labels, test_instance, k=0):",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=0):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "CRP",
      "lineno": 3,
      "original_line": "def naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):",
      "mutated_line": "def naive_bayes_multiclass(train_data, train_labels, test_instance, k=0):",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=0):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "CRP",
      "lineno": 3,
      "original_line": "def naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):",
      "mutated_line": "def naive_bayes_multiclass(train_data, train_labels, test_instance, k=-1):",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=-1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "prior_probabilities = class_counts / len(train_labels)",
      "mutated_line": "prior_probabilities = class_counts * len(train_labels)",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts * len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "prior_probabilities = class_counts / len(train_labels)",
      "mutated_line": "prior_probabilities = class_counts // len(train_labels)",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts // len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "ASR",
      "lineno": 38,
      "original_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else (1 - feature_probabilities[unique_class][j])",
      "mutated_line": "posterior_probability /= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability /= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "CRP",
      "lineno": 18,
      "original_line": "unique_classes, class_counts = np.unique(train_labels, return_counts=True)",
      "mutated_line": "(unique_classes, class_counts) = np.unique(train_labels, return_counts=False)",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=False)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 31,
      "original_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "mutated_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) * (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) * (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 31,
      "original_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "mutated_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) // (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) // (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "ROR",
      "lineno": 28,
      "original_line": "class_data = [data for data, label in zip(train_data, train_labels) if label == unique_class]",
      "mutated_line": "class_data = [data for (data, label) in zip(train_data, train_labels) if label != unique_class]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label != unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 31,
      "original_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "mutated_line": "feature_probabilities[unique_class] = [(np.sum(feature) - k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) - k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 31,
      "original_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "mutated_line": "feature_probabilities[unique_class] = [np.sum(feature) * k / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [np.sum(feature) * k / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 31,
      "original_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "mutated_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] - k * len(test_instance)) for feature in zip(*class_data)]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] - k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 31,
      "original_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "mutated_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] * (k * len(test_instance))) for feature in zip(*class_data)]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] * (k * len(test_instance))) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 38,
      "original_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else (1 - feature_probabilities[unique_class][j])",
      "mutated_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 + feature_probabilities[unique_class][j]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 + feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 38,
      "original_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else (1 - feature_probabilities[unique_class][j])",
      "mutated_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 * feature_probabilities[unique_class][j]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 * feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 31,
      "original_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "mutated_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k / len(test_instance)) for feature in zip(*class_data)]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k / len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 31,
      "original_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "mutated_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + (k + len(test_instance))) for feature in zip(*class_data)]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + (k + len(test_instance))) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "AOR",
      "lineno": 31,
      "original_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]",
      "mutated_line": "feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k ** len(test_instance)) for feature in zip(*class_data)]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k ** len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "CRP",
      "lineno": 38,
      "original_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else (1 - feature_probabilities[unique_class][j])",
      "mutated_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else 2 - feature_probabilities[unique_class][j]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 2 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "CRP",
      "lineno": 38,
      "original_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else (1 - feature_probabilities[unique_class][j])",
      "mutated_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else 0 - feature_probabilities[unique_class][j]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 0 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "CRP",
      "lineno": 38,
      "original_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else (1 - feature_probabilities[unique_class][j])",
      "mutated_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else 0 - feature_probabilities[unique_class][j]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else 0 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    },
    {
      "operator": "CRP",
      "lineno": 38,
      "original_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else (1 - feature_probabilities[unique_class][j])",
      "mutated_line": "posterior_probability *= feature_probabilities[unique_class][j] if feature else -1 - feature_probabilities[unique_class][j]",
      "code": "import numpy as np\n\ndef naive_bayes_multiclass(train_data, train_labels, test_instance, k=1):\n    \"\"\"\n    Naive Bayes classifier for multiclass classification with Laplace smoothing.\n\n    Args:\n    - train_data (list of lists): Training data.\n    - train_labels (list): Corresponding class labels for the training data.\n    - test_instance (list): Test instance to predict the class label for.\n    - k (int, optional): Smoothing constant. Defaults to 1.\n\n    Returns:\n    - int: Predicted class label for the test instance.\n    \"\"\"\n    (unique_classes, class_counts) = np.unique(train_labels, return_counts=True)\n    prior_probabilities = class_counts / len(train_labels)\n    feature_probabilities = {}\n    for (i, unique_class) in enumerate(unique_classes):\n        class_data = [data for (data, label) in zip(train_data, train_labels) if label == unique_class]\n        feature_probabilities[unique_class] = [(np.sum(feature) + k) / (class_counts[i] + k * len(test_instance)) for feature in zip(*class_data)]\n    posterior_probabilities = []\n    for (i, unique_class) in enumerate(unique_classes):\n        posterior_probability = prior_probabilities[i]\n        for (j, feature) in enumerate(test_instance):\n            posterior_probability *= feature_probabilities[unique_class][j] if feature else -1 - feature_probabilities[unique_class][j]\n        posterior_probabilities.append(posterior_probability)\n    return unique_classes[np.argmax(posterior_probabilities)]"
    }
  ]
}