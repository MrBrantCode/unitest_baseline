{
  "task_id": "cf_4839",
  "entry_point": "naive_bayes",
  "mutant_count": 91,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = (classes.count(class_label) + 1) * (len(classes) + len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) * (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = (classes.count(class_label) + 1) // (len(classes) + len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) // (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = (classes.count(class_label) - 1) / (len(classes) + len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) - 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = classes.count(class_label) * 1 / (len(classes) + len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = classes.count(class_label) * 1 / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) - len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) - len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) * len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) * len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 24,
      "original_line": "for feature_idx, _ in enumerate(data[0]):",
      "mutated_line": "for (feature_idx, _) in enumerate(data[1]):",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[1]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 24,
      "original_line": "for feature_idx, _ in enumerate(data[0]):",
      "mutated_line": "for (feature_idx, _) in enumerate(data[-1]):",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[-1]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 24,
      "original_line": "for feature_idx, _ in enumerate(data[0]):",
      "mutated_line": "for (feature_idx, _) in enumerate(data[1]):",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[1]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = (classes.count(class_label) + 2) / (len(classes) + len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 2) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = (classes.count(class_label) + 0) / (len(classes) + len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 0) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = (classes.count(class_label) + 0) / (len(classes) + len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 0) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 20,
      "original_line": "class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))",
      "mutated_line": "class_priors[class_label] = (classes.count(class_label) + -1) / (len(classes) + len(set(classes)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + -1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 32,
      "original_line": "mean = sum(class_data) / len(class_data)",
      "mutated_line": "mean = sum(class_data) * len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) * len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 32,
      "original_line": "mean = sum(class_data) / len(class_data)",
      "mutated_line": "mean = sum(class_data) // len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) // len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x - mean) ** 2 for x in class_data)) * len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) * len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x - mean) ** 2 for x in class_data)) // len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) // len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "ASR",
      "lineno": 43,
      "original_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-9))",
      "mutated_line": "probabilities[class_label] -= log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] -= log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "ASR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] -= log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] -= log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "ROR",
      "lineno": 26,
      "original_line": "class_data = [row[feature_idx] for row, class_ in zip(data, classes) if class_ == class_label]",
      "mutated_line": "class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ != class_label]",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ != class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "if isinstance(class_data[0], str):  # Categorical feature",
      "mutated_line": "if isinstance(class_data[1], str):",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[1], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "if isinstance(class_data[0], str):  # Categorical feature",
      "mutated_line": "if isinstance(class_data[-1], str):",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[-1], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "if isinstance(class_data[0], str):  # Categorical feature",
      "mutated_line": "if isinstance(class_data[1], str):",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[1], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) * (len(class_data) + len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) * (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) // (len(class_data) + len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) // (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) - 1) / (len(class_data) + len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) - 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = class_data.count(feature_value) * 1 / (len(class_data) + len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = class_data.count(feature_value) * 1 / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) - len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) - len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) * len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) * len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 / 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 / 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 + 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 + 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log((1 / variance ** 0.5) ** 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log((1 / variance ** 0.5) ** 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 2) / (len(class_data) + len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 2) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 0) / (len(class_data) + len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 0) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 0) / (len(class_data) + len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 0) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))",
      "mutated_line": "likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + -1) / (len(class_data) + len(set(class_data)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + -1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x - mean) * 2 for x in class_data)) / len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) * 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum((x - mean + 2 for x in class_data)) / len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum((x - mean + 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 43,
      "original_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-9))",
      "mutated_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1.000000001))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1.000000001))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 43,
      "original_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-9))",
      "mutated_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, -0.999999999))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, -0.999999999))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 43,
      "original_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-9))",
      "mutated_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 0))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 0))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 43,
      "original_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-9))",
      "mutated_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 43,
      "original_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-9))",
      "mutated_line": "probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, -1e-09))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, -1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 * variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 * variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 // variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 // variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * (2.71828 * (-(feature_value - mean) ** 2 / (2 * variance))))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * (2.71828 * (-(feature_value - mean) ** 2 / (2 * variance))))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * (2.71828 + -(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * (2.71828 + -(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x + mean) ** 2 for x in class_data)) / len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x + mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x * mean) ** 2 for x in class_data)) / len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x * mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x - mean) ** 3 for x in class_data)) / len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 3 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x - mean) ** 1 for x in class_data)) / len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 1 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x - mean) ** 0 for x in class_data)) / len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 0 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x - mean) ** 1 for x in class_data)) / len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 1 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 33,
      "original_line": "variance = sum((x - mean) ** 2 for x in class_data) / len(class_data)",
      "mutated_line": "variance = sum(((x - mean) ** -2 for x in class_data)) / len(class_data)",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** -2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(2 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(2 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(0 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(0 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(0 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(0 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(-1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(-1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / (variance * 0.5) * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / (variance * 0.5) * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / (variance + 0.5) * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / (variance + 0.5) * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 3.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 3.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 1.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 1.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 0 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 0 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 1 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 1 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * -2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * -2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 * (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 * (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 // (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 // (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 1.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 1.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** -0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** -0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 1 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 1 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** -0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** -0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "UOI",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (+(feature_value - mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (+(feature_value - mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 / variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 / variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 + variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (2 + variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / 2 ** variance))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / 2 ** variance))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-((feature_value - mean) * 2) / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-((feature_value - mean) * 2) / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean + 2) / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean + 2) / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (3 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (3 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (1 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (1 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (0 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (0 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (1 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (1 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (-2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 2 / (-2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value + mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value + mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "AOR",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value * mean) ** 2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value * mean) ** 2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 3 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 3 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 1 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 1 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 0 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 0 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 1 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** 1 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "probabilities[class_label] += log((1 / (variance ** 0.5)) * (2.71828 ** (-((feature_value - mean) ** 2) / (2 * variance))))",
      "mutated_line": "probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** -2 / (2 * variance)))",
      "code": "from collections import defaultdict\nfrom math import log\nfrom typing import Callable\n\ndef naive_bayes(data: list, classes: list) -> Callable:\n    \"\"\"\n    Train a Naive Bayes classifier that handles different types of features and zero probabilities.\n\n    Args:\n    data (list): 2D array of training data.\n    classes (list): 1D array of target variable.\n\n    Returns:\n    Callable: Function to make predictions on new data.\n    \"\"\"\n    class_priors = {}\n    for class_label in set(classes):\n        class_priors[class_label] = (classes.count(class_label) + 1) / (len(classes) + len(set(classes)))\n    likelihoods = defaultdict(dict)\n    for (feature_idx, _) in enumerate(data[0]):\n        for class_label in set(classes):\n            class_data = [row[feature_idx] for (row, class_) in zip(data, classes) if class_ == class_label]\n            if isinstance(class_data[0], str):\n                likelihoods[feature_idx][class_label] = {}\n                for feature_value in set(class_data):\n                    likelihoods[feature_idx][class_label][feature_value] = (class_data.count(feature_value) + 1) / (len(class_data) + len(set(class_data)))\n            else:\n                mean = sum(class_data) / len(class_data)\n                variance = sum(((x - mean) ** 2 for x in class_data)) / len(class_data)\n                likelihoods[feature_idx][class_label] = (mean, variance)\n\n    def predict(new_instance):\n        probabilities = {}\n        for class_label in class_priors:\n            probabilities[class_label] = log(class_priors[class_label])\n            for (feature_idx, feature_value) in enumerate(new_instance):\n                if isinstance(feature_value, str):\n                    probabilities[class_label] += log(likelihoods[feature_idx][class_label].get(feature_value, 1e-09))\n                else:\n                    (mean, variance) = likelihoods[feature_idx][class_label]\n                    probabilities[class_label] += log(1 / variance ** 0.5 * 2.71828 ** (-(feature_value - mean) ** -2 / (2 * variance)))\n        return max(probabilities, key=probabilities.get)\n    return predict"
    }
  ]
}