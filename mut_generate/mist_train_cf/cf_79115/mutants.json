{
  "task_id": "cf_79115",
  "entry_point": "map_reduce_optimization",
  "mutant_count": 24,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 2,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 13,
      "original_line": "workload_size = len(data) // num_reducers",
      "mutated_line": "workload_size = len(data) / num_reducers",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) / num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 13,
      "original_line": "workload_size = len(data) // num_reducers",
      "mutated_line": "workload_size = len(data) * num_reducers",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) * num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "start = i * workload_size",
      "mutated_line": "start = i / workload_size",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i / workload_size\n        end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "start = i * workload_size",
      "mutated_line": "start = i + workload_size",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i + workload_size\n        end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "start = i * workload_size",
      "mutated_line": "start = i ** workload_size",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i ** workload_size\n        end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "ROR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) * workload_size if i <= num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i <= num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "ROR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) * workload_size if i >= num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i >= num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "ROR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) * workload_size if i != num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i != num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) / workload_size if i < num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) / workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = i + 1 + workload_size if i < num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = i + 1 + workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) ** workload_size if i < num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) ** workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) * workload_size if i < num_reducers + 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i < num_reducers + 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) * workload_size if i < num_reducers * 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i < num_reducers * 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i - 1) * workload_size if i < num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i - 1) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = i * 1 * workload_size if i < num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = i * 1 * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) * workload_size if i < num_reducers - 2 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i < num_reducers - 2 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) * workload_size if i < num_reducers - 0 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i < num_reducers - 0 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) * workload_size if i < num_reducers - 0 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i < num_reducers - 0 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 1) * workload_size if i < num_reducers - -1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 1) * workload_size if i < num_reducers - -1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 2) * workload_size if i < num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 2) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 0) * workload_size if i < num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 0) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + 0) * workload_size if i < num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + 0) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "end = (i + 1) * workload_size if i < num_reducers - 1 else len(data)",
      "mutated_line": "end = (i + -1) * workload_size if i < num_reducers - 1 else len(data)",
      "code": "def map_reduce_optimization(data, num_reducers):\n    \"\"\"\n    This function optimizes the MapReduce task by mitigating data skew.\n    \n    It takes in two parameters: \n    data (list): The input data to be processed.\n    num_reducers (int): The number of reducers available.\n    \n    The function returns a list of lists where each sublist contains the data to be processed by a reducer.\n    \"\"\"\n    workload_size = len(data) // num_reducers\n    reducer_workloads = []\n    for i in range(num_reducers):\n        start = i * workload_size\n        end = (i + -1) * workload_size if i < num_reducers - 1 else len(data)\n        reducer_workloads.append(data[start:end])\n    return reducer_workloads"
    }
  ]
}