{
  "task_id": "cf_5792",
  "entry_point": "tokenize_text",
  "mutant_count": 4,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "import re\n\ndef tokenize_text(text):\n    \"\"\"\"\"\"\n    text = re.sub('\\n', ' ', text)\n    tokens = re.findall('[\\\\w\\\\\\'\\\\-]+|[.,!?;()\"\\\\\\']', text)\n    return tokens"
    },
    {
      "operator": "CRP",
      "lineno": 14,
      "original_line": "text = re.sub('\\n', ' ', text)",
      "mutated_line": "tokens = re.findall('[\\\\w\\\\\\'\\\\-]+|[.,!?;()\"\\\\\\']', text)",
      "code": "import re\n\ndef tokenize_text(text):\n    \"\"\"\n    Tokenize the given text into a list of tokens.\n\n    Args:\n    text (str): The input text to be tokenized.\n\n    Returns:\n    list: A list of tokens.\n    \"\"\"\n    text = re.sub('', ' ', text)\n    tokens = re.findall('[\\\\w\\\\\\'\\\\-]+|[.,!?;()\"\\\\\\']', text)\n    return tokens"
    },
    {
      "operator": "CRP",
      "lineno": 14,
      "original_line": "text = re.sub('\\n', ' ', text)",
      "mutated_line": "tokens = re.findall('[\\\\w\\\\\\'\\\\-]+|[.,!?;()\"\\\\\\']', text)",
      "code": "import re\n\ndef tokenize_text(text):\n    \"\"\"\n    Tokenize the given text into a list of tokens.\n\n    Args:\n    text (str): The input text to be tokenized.\n\n    Returns:\n    list: A list of tokens.\n    \"\"\"\n    text = re.sub('\\n', '', text)\n    tokens = re.findall('[\\\\w\\\\\\'\\\\-]+|[.,!?;()\"\\\\\\']', text)\n    return tokens"
    },
    {
      "operator": "CRP",
      "lineno": 17,
      "original_line": "tokens = re.findall(r'[\\w\\'\\-]+|[.,!?;()\"\\']', text)",
      "mutated_line": "tokens = re.findall('', text)",
      "code": "import re\n\ndef tokenize_text(text):\n    \"\"\"\n    Tokenize the given text into a list of tokens.\n\n    Args:\n    text (str): The input text to be tokenized.\n\n    Returns:\n    list: A list of tokens.\n    \"\"\"\n    text = re.sub('\\n', ' ', text)\n    tokens = re.findall('', text)\n    return tokens"
    }
  ]
}