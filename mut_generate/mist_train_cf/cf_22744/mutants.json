{
  "task_id": "cf_22744",
  "entry_point": "tokenize_and_count",
  "mutant_count": 29,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "current_word = \"\"",
      "mutated_line": "current_word = 'MUTATED'",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = 'MUTATED'\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "LCR",
      "lineno": 8,
      "original_line": "if char.isalpha() or char == \"'\":",
      "mutated_line": "if char.isalpha() and char == \"'\":",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() and char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "ASR",
      "lineno": 9,
      "original_line": "current_word += char",
      "mutated_line": "current_word -= char",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word -= char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "ROR",
      "lineno": 23,
      "original_line": "if current_word in tokens:",
      "mutated_line": "if current_word not in tokens:",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word not in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "ASR",
      "lineno": 25,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] -= 1",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] -= 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "ROR",
      "lineno": 8,
      "original_line": "if char.isalpha() or char == \"'\":",
      "mutated_line": "if char.isalpha() or char != \"'\":",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char != \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "LCR",
      "lineno": 10,
      "original_line": "elif char.isspace() or char in \".,!?\":",
      "mutated_line": "elif char.isspace() and char in '.,!?':",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() and char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 25,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] += 2",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 2\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 25,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] += 0",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 0\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 25,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] += 0",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 0\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 25,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] += -1",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += -1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "if char.isalpha() or char == \"'\":",
      "mutated_line": "if char.isalpha() or char == '':",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == '':\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "ROR",
      "lineno": 10,
      "original_line": "elif char.isspace() or char in \".,!?\":",
      "mutated_line": "elif char.isspace() or char not in '.,!?':",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char not in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 28,
      "original_line": "counts.append(1)",
      "mutated_line": "counts.append(2)",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(2)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 28,
      "original_line": "counts.append(1)",
      "mutated_line": "counts.append(0)",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(0)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 28,
      "original_line": "counts.append(1)",
      "mutated_line": "counts.append(0)",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(0)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 28,
      "original_line": "counts.append(1)",
      "mutated_line": "counts.append(-1)",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(-1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 10,
      "original_line": "elif char.isspace() or char in \".,!?\":",
      "mutated_line": "elif char.isspace() or char in '':",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "ROR",
      "lineno": 13,
      "original_line": "if current_word in tokens:",
      "mutated_line": "if current_word not in tokens:",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word not in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "ASR",
      "lineno": 15,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] -= 1",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] -= 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 19,
      "original_line": "current_word = \"\"",
      "mutated_line": "current_word = 'MUTATED'",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = 'MUTATED'\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] += 2",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 2\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] += 0",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 0\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] += 0",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 0\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "counts[index] += 1",
      "mutated_line": "counts[index] += -1",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += -1\n                else:\n                    tokens.append(current_word)\n                    counts.append(1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 18,
      "original_line": "counts.append(1)",
      "mutated_line": "counts.append(2)",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(2)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 18,
      "original_line": "counts.append(1)",
      "mutated_line": "counts.append(0)",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(0)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 18,
      "original_line": "counts.append(1)",
      "mutated_line": "counts.append(0)",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(0)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    },
    {
      "operator": "CRP",
      "lineno": 18,
      "original_line": "counts.append(1)",
      "mutated_line": "counts.append(-1)",
      "code": "def tokenize_and_count(sentence):\n    sentence = sentence.strip()\n    tokens = []\n    counts = []\n    current_word = ''\n    for char in sentence:\n        if char.isalpha() or char == \"'\":\n            current_word += char\n        elif char.isspace() or char in '.,!?':\n            if current_word:\n                current_word = current_word.lower()\n                if current_word in tokens:\n                    index = tokens.index(current_word)\n                    counts[index] += 1\n                else:\n                    tokens.append(current_word)\n                    counts.append(-1)\n                current_word = ''\n    if current_word:\n        current_word = current_word.lower()\n        if current_word in tokens:\n            index = tokens.index(current_word)\n            counts[index] += 1\n        else:\n            tokens.append(current_word)\n            counts.append(1)\n    return tuple(zip(tokens, counts))"
    }
  ]
}