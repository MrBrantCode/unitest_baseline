{
  "task_id": "cf_37788",
  "entry_point": "extract_domain_names",
  "mutant_count": 6,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "if domain.startswith(\"www.\"):",
      "mutated_line": "if domain.startswith(''):",
      "code": "from urllib.parse import urlparse\n\ndef extract_domain_names(urls):\n    unique_domains = set()\n    for url in urls:\n        parsed_url = urlparse(url)\n        domain = parsed_url.netloc\n        if domain.startswith(''):\n            domain = domain[4:]\n        unique_domains.add(domain)\n    return list(unique_domains)"
    },
    {
      "operator": "CRP",
      "lineno": 9,
      "original_line": "domain = domain[4:]  # Remove \"www.\" prefix",
      "mutated_line": "domain = domain[5:]",
      "code": "from urllib.parse import urlparse\n\ndef extract_domain_names(urls):\n    unique_domains = set()\n    for url in urls:\n        parsed_url = urlparse(url)\n        domain = parsed_url.netloc\n        if domain.startswith('www.'):\n            domain = domain[5:]\n        unique_domains.add(domain)\n    return list(unique_domains)"
    },
    {
      "operator": "CRP",
      "lineno": 9,
      "original_line": "domain = domain[4:]  # Remove \"www.\" prefix",
      "mutated_line": "domain = domain[3:]",
      "code": "from urllib.parse import urlparse\n\ndef extract_domain_names(urls):\n    unique_domains = set()\n    for url in urls:\n        parsed_url = urlparse(url)\n        domain = parsed_url.netloc\n        if domain.startswith('www.'):\n            domain = domain[3:]\n        unique_domains.add(domain)\n    return list(unique_domains)"
    },
    {
      "operator": "CRP",
      "lineno": 9,
      "original_line": "domain = domain[4:]  # Remove \"www.\" prefix",
      "mutated_line": "domain = domain[0:]",
      "code": "from urllib.parse import urlparse\n\ndef extract_domain_names(urls):\n    unique_domains = set()\n    for url in urls:\n        parsed_url = urlparse(url)\n        domain = parsed_url.netloc\n        if domain.startswith('www.'):\n            domain = domain[0:]\n        unique_domains.add(domain)\n    return list(unique_domains)"
    },
    {
      "operator": "CRP",
      "lineno": 9,
      "original_line": "domain = domain[4:]  # Remove \"www.\" prefix",
      "mutated_line": "domain = domain[1:]",
      "code": "from urllib.parse import urlparse\n\ndef extract_domain_names(urls):\n    unique_domains = set()\n    for url in urls:\n        parsed_url = urlparse(url)\n        domain = parsed_url.netloc\n        if domain.startswith('www.'):\n            domain = domain[1:]\n        unique_domains.add(domain)\n    return list(unique_domains)"
    },
    {
      "operator": "CRP",
      "lineno": 9,
      "original_line": "domain = domain[4:]  # Remove \"www.\" prefix",
      "mutated_line": "domain = domain[-4:]",
      "code": "from urllib.parse import urlparse\n\ndef extract_domain_names(urls):\n    unique_domains = set()\n    for url in urls:\n        parsed_url = urlparse(url)\n        domain = parsed_url.netloc\n        if domain.startswith('www.'):\n            domain = domain[-4:]\n        unique_domains.add(domain)\n    return list(unique_domains)"
    }
  ]
}