{
  "task_id": "cf_5038",
  "entry_point": "update_weights",
  "mutant_count": 69,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 2,
      "original_line": "v = 0",
      "mutated_line": "v = 1",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 1\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 2,
      "original_line": "v = 0",
      "mutated_line": "v = -1",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = -1\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 2,
      "original_line": "v = 0",
      "mutated_line": "v = 1",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 1\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "ASR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights += learning_rate * gradients / (epsilon + v ** 0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights += learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "LCR",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch % decay_interval == 0 or epoch != 0:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 or epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "ASR",
      "lineno": 5,
      "original_line": "learning_rate *= decay_factor",
      "mutated_line": "learning_rate /= decay_factor",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate /= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 * x * (x * weights - y) - lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) - lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 * x * (x * weights - y) * lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) * lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v - (1 - rho) * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v - (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v * ((1 - rho) * gradients ** 2)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v * ((1 - rho) * gradients ** 2)\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients * (epsilon + v ** 0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients * (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients // (epsilon + v ** 0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients // (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "ROR",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch % decay_interval != 0 and epoch != 0:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval != 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "ROR",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch % decay_interval == 0 and epoch == 0:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch == 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 * x / (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x / (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 * x + (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x + (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = (2 * x) ** (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = (2 * x) ** (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho / v + (1 - rho) * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho / v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho + v + (1 - rho) * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho + v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho ** v + (1 - rho) * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho ** v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho) / gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) / gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho + gradients ** 2)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho + gradients ** 2)\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho) ** gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) ** gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate / gradients / (epsilon + v ** 0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate / gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= (learning_rate + gradients) / (epsilon + v ** 0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= (learning_rate + gradients) / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate ** gradients / (epsilon + v ** 0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate ** gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients / (epsilon - v ** 0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon - v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients / (epsilon * v ** 0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon * v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch * decay_interval == 0 and epoch != 0:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch * decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch + decay_interval == 0 and epoch != 0:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch + decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch % decay_interval == 1 and epoch != 0:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 1 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch % decay_interval == -1 and epoch != 0:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == -1 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch % decay_interval == 1 and epoch != 0:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 1 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch % decay_interval == 0 and epoch != 1:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 1:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch % decay_interval == 0 and epoch != -1:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != -1:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "if epoch % decay_interval == 0 and epoch != 0:",
      "mutated_line": "if epoch % decay_interval == 0 and epoch != 1:",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 1:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 / x * (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 / x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = (2 + x) * (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = (2 + x) * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 ** x * (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 ** x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 * x * (x * weights + y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights + y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 * x * (x * weights * y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights * y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 + rho) * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 + rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + 1 * rho * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + 1 * rho * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho) * (gradients * 2)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * (gradients * 2)\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho) * (gradients + 2)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * (gradients + 2)\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients / (epsilon + v * 0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v * 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients / (epsilon + (v + 0.5))",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + (v + 0.5))\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 3 * x * (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 3 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 1 * x * (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 1 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 0 * x * (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 0 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 1 * x * (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 1 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = -2 * x * (x * weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = -2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 * x * (x / weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x / weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 * x * (x + weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x + weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradients = (2 * x * (x * weights - y) + lambda_val)",
      "mutated_line": "gradients = 2 * x * (x ** weights - y) + lambda_val",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x ** weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (2 - rho) * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (2 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (0 - rho) * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (0 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (0 - rho) * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (0 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (-1 - rho) * gradients ** 2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (-1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho) * gradients ** 3",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 3\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho) * gradients ** 1",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 1\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho) * gradients ** 0",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 0\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho) * gradients ** 1",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 1\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "v = rho * v + (1 - rho) * gradients ** 2",
      "mutated_line": "v = rho * v + (1 - rho) * gradients ** -2",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** -2\n        weights -= learning_rate * gradients / (epsilon + v ** 0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients / (epsilon + v ** 1.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 1.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients / (epsilon + v ** -0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** -0.5)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients / (epsilon + v ** 0)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 0)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients / (epsilon + v ** 1)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** 1)\n    return weights"
    },
    {
      "operator": "CRP",
      "lineno": 8,
      "original_line": "weights -= learning_rate * gradients / (epsilon + v ** 0.5)",
      "mutated_line": "weights -= learning_rate * gradients / (epsilon + v ** -0.5)",
      "code": "def update_weights(weights, x, y, learning_rate, decay_factor, decay_interval, rho, epsilon, lambda_val, num_epochs):\n    v = 0\n    for epoch in range(num_epochs):\n        if epoch % decay_interval == 0 and epoch != 0:\n            learning_rate *= decay_factor\n        gradients = 2 * x * (x * weights - y) + lambda_val\n        v = rho * v + (1 - rho) * gradients ** 2\n        weights -= learning_rate * gradients / (epsilon + v ** -0.5)\n    return weights"
    }
  ]
}