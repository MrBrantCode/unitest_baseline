{
  "task_id": "cf_63922",
  "entry_point": "parse_url",
  "mutant_count": 38,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "LCR",
      "lineno": 19,
      "original_line": "if \"http://\" not in url and \"https://\" not in url:",
      "mutated_line": "url = 'http://' + url",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url or 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "ROR",
      "lineno": 19,
      "original_line": "if \"http://\" not in url and \"https://\" not in url:",
      "mutated_line": "url = 'http://' + url",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "ROR",
      "lineno": 19,
      "original_line": "if \"http://\" not in url and \"https://\" not in url:",
      "mutated_line": "url = 'http://' + url",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "url = \"http://\" + url",
      "mutated_line": "url = 'http://' - url",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' - url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "url = \"http://\" + url",
      "mutated_line": "url = 'http://' * url",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' * url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "ROR",
      "lineno": 32,
      "original_line": "subdomain = \".\".join(subdomain_list) if len(subdomain_list) > 0 else None",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) >= 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) >= 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "ROR",
      "lineno": 32,
      "original_line": "subdomain = \".\".join(subdomain_list) if len(subdomain_list) > 0 else None",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) <= 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) <= 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "ROR",
      "lineno": 32,
      "original_line": "subdomain = \".\".join(subdomain_list) if len(subdomain_list) > 0 else None",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) != 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) != 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 42,
      "original_line": "\"protocol\": protocol,",
      "mutated_line": "return {'': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 43,
      "original_line": "\"domain\": domain,",
      "mutated_line": "return {'protocol': protocol, '': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, '': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 44,
      "original_line": "\"subdomain\": subdomain,",
      "mutated_line": "return {'protocol': protocol, 'domain': domain, '': subdomain, 'path': path, 'query_params': query_params}",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, '': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 45,
      "original_line": "\"path\": path,",
      "mutated_line": "return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, '': path, 'query_params': query_params}",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, '': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "\"query_params\": query_params",
      "mutated_line": "return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, '': query_params}",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, '': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 19,
      "original_line": "if \"http://\" not in url and \"https://\" not in url:",
      "mutated_line": "url = 'http://' + url",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if '' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 19,
      "original_line": "if \"http://\" not in url and \"https://\" not in url:",
      "mutated_line": "url = 'http://' + url",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and '' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 20,
      "original_line": "url = \"http://\" + url",
      "mutated_line": "url = '' + url",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = '' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 29,
      "original_line": "domain = \".\".join(parsed_url.netloc.split(\".\")[-2:])",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = ''.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 31,
      "original_line": "subdomain_list = parsed_url.netloc.split(\".\")[:-2]",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "UOI",
      "lineno": 31,
      "original_line": "subdomain_list = parsed_url.netloc.split(\".\")[:-2]",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:+2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 32,
      "original_line": "subdomain = \".\".join(subdomain_list) if len(subdomain_list) > 0 else None",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 1 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 1 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 32,
      "original_line": "subdomain = \".\".join(subdomain_list) if len(subdomain_list) > 0 else None",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > -1 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > -1 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 32,
      "original_line": "subdomain = \".\".join(subdomain_list) if len(subdomain_list) > 0 else None",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 1 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 1 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 50,
      "original_line": "print(\"Invalid URL, please try again!\")",
      "mutated_line": "print('')",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 51,
      "original_line": "print(\"Error: \", str(e))",
      "mutated_line": "print('', str(e))",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 29,
      "original_line": "domain = \".\".join(parsed_url.netloc.split(\".\")[-2:])",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "UOI",
      "lineno": 29,
      "original_line": "domain = \".\".join(parsed_url.netloc.split(\".\")[-2:])",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[+2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 31,
      "original_line": "subdomain_list = parsed_url.netloc.split(\".\")[:-2]",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-3]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 31,
      "original_line": "subdomain_list = parsed_url.netloc.split(\".\")[:-2]",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-1]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 31,
      "original_line": "subdomain_list = parsed_url.netloc.split(\".\")[:-2]",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-0]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 31,
      "original_line": "subdomain_list = parsed_url.netloc.split(\".\")[:-2]",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-1]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 31,
      "original_line": "subdomain_list = parsed_url.netloc.split(\".\")[:-2]",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:--2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 32,
      "original_line": "subdomain = \".\".join(subdomain_list) if len(subdomain_list) > 0 else None",
      "mutated_line": "subdomain = ''.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = ''.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 29,
      "original_line": "domain = \".\".join(parsed_url.netloc.split(\".\")[-2:])",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-3:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 29,
      "original_line": "domain = \".\".join(parsed_url.netloc.split(\".\")[-2:])",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-1:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 29,
      "original_line": "domain = \".\".join(parsed_url.netloc.split(\".\")[-2:])",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-0:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 29,
      "original_line": "domain = \".\".join(parsed_url.netloc.split(\".\")[-2:])",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[-1:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    },
    {
      "operator": "CRP",
      "lineno": 29,
      "original_line": "domain = \".\".join(parsed_url.netloc.split(\".\")[-2:])",
      "mutated_line": "subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None",
      "code": "from urllib.parse import urlparse, parse_qs\n\ndef parse_url(url):\n    \"\"\"\n    This function takes a URL as input, extracts its components, \n    and returns them. The function handles cases where the URL might \n    be missing certain components, has extra slashes, or is invalid.\n\n    Args:\n        url (str): The URL to be parsed.\n\n    Returns:\n        dict: A dictionary containing the protocol, domain, subdomain, \n        path, and query parameters of the URL.\n    \"\"\"\n    try:\n        if 'http://' not in url and 'https://' not in url:\n            url = 'http://' + url\n        parsed_url = urlparse(url)\n        protocol = parsed_url.scheme\n        domain = '.'.join(parsed_url.netloc.split('.')[--2:])\n        subdomain_list = parsed_url.netloc.split('.')[:-2]\n        subdomain = '.'.join(subdomain_list) if len(subdomain_list) > 0 else None\n        path = parsed_url.path\n        query_params = parse_qs(parsed_url.query)\n        return {'protocol': protocol, 'domain': domain, 'subdomain': subdomain, 'path': path, 'query_params': query_params}\n    except Exception as e:\n        print('Invalid URL, please try again!')\n        print('Error: ', str(e))\n        return None"
    }
  ]
}