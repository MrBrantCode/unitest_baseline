{
  "task_id": "cf_6957",
  "entry_point": "filter_unwanted_words",
  "mutant_count": 20,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 2,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "'en': {'the', 'and', 'a', 'of', 'to'},  # Add more common words for each language",
      "mutated_line": "common_words = {'': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 16,
      "original_line": "'es': {'de', 'la', 'que', 'el', 'en'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, '': {'de', 'la', 'que', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, '': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "ROR",
      "lineno": 29,
      "original_line": "if word.lower() not in unwanted_words_set:",
      "mutated_line": "if word.lower() in unwanted_words_set:",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "'en': {'the', 'and', 'a', 'of', 'to'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "'en': {'the', 'and', 'a', 'of', 'to'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', '', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', '', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "'en': {'the', 'and', 'a', 'of', 'to'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', 'and', '', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', '', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "'en': {'the', 'and', 'a', 'of', 'to'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', 'and', 'a', '', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', '', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "'en': {'the', 'and', 'a', 'of', 'to'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', 'and', 'a', 'of', ''}, 'es': {'de', 'la', 'que', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', ''}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 16,
      "original_line": "'es': {'de', 'la', 'que', 'el', 'en'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'', 'la', 'que', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 16,
      "original_line": "'es': {'de', 'la', 'que', 'el', 'en'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', '', 'que', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', '', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 16,
      "original_line": "'es': {'de', 'la', 'que', 'el', 'en'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', '', 'el', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', '', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 16,
      "original_line": "'es': {'de', 'la', 'que', 'el', 'en'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', '', 'en'}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', '', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 16,
      "original_line": "'es': {'de', 'la', 'que', 'el', 'en'},  # Add more common words for each language",
      "mutated_line": "common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', ''}}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', ''}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 32,
      "original_line": "return ' '.join(filtered_words)",
      "mutated_line": "return ''.join(filtered_words)",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ''.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "language_counts = {lang: sum(1 for word in words if word.lower() in common_words[lang]) for lang in common_words}",
      "mutated_line": "language_counts = {lang: sum((2 for word in words if word.lower() in common_words[lang])) for lang in common_words}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((2 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "language_counts = {lang: sum(1 for word in words if word.lower() in common_words[lang]) for lang in common_words}",
      "mutated_line": "language_counts = {lang: sum((0 for word in words if word.lower() in common_words[lang])) for lang in common_words}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((0 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "language_counts = {lang: sum(1 for word in words if word.lower() in common_words[lang]) for lang in common_words}",
      "mutated_line": "language_counts = {lang: sum((0 for word in words if word.lower() in common_words[lang])) for lang in common_words}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((0 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "language_counts = {lang: sum(1 for word in words if word.lower() in common_words[lang]) for lang in common_words}",
      "mutated_line": "language_counts = {lang: sum((-1 for word in words if word.lower() in common_words[lang])) for lang in common_words}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((-1 for word in words if word.lower() in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    },
    {
      "operator": "ROR",
      "lineno": 21,
      "original_line": "language_counts = {lang: sum(1 for word in words if word.lower() in common_words[lang]) for lang in common_words}",
      "mutated_line": "language_counts = {lang: sum((1 for word in words if word.lower() not in common_words[lang])) for lang in common_words}",
      "code": "def filter_unwanted_words(paragraph, unwanted_words):\n    \"\"\"\n    Filter out unwanted words from a given paragraph of text, ignoring case sensitivity.\n    \n    Parameters:\n    paragraph (str): The input paragraph to be filtered.\n    unwanted_words (dict): A dictionary of language-specific unwanted words where each key is a language code and its corresponding value is a set of unwanted words.\n    \n    Returns:\n    str: The filtered paragraph after removing the unwanted words.\n    \"\"\"\n    common_words = {'en': {'the', 'and', 'a', 'of', 'to'}, 'es': {'de', 'la', 'que', 'el', 'en'}}\n    words = paragraph.split()\n    language_counts = {lang: sum((1 for word in words if word.lower() not in common_words[lang])) for lang in common_words}\n    detected_language = max(language_counts, key=language_counts.get)\n    filtered_words = []\n    unwanted_words_set = set(unwanted_words.get(detected_language, set()))\n    for word in words:\n        if word.lower() not in unwanted_words_set:\n            filtered_words.append(word)\n    return ' '.join(filtered_words)"
    }
  ]
}