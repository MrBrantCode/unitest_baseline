{
  "task_id": "cf_93737",
  "entry_point": "classify_articles",
  "mutant_count": 17,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "spam_words = [\"spam\", \"offer\", \"free\", \"amazing\"]",
      "mutated_line": "spam_words = ['', 'offer', 'free', 'amazing']",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "spam_words = [\"spam\", \"offer\", \"free\", \"amazing\"]",
      "mutated_line": "spam_words = ['spam', '', 'free', 'amazing']",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', '', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "spam_words = [\"spam\", \"offer\", \"free\", \"amazing\"]",
      "mutated_line": "spam_words = ['spam', 'offer', '', 'amazing']",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', '', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "spam_words = [\"spam\", \"offer\", \"free\", \"amazing\"]",
      "mutated_line": "spam_words = ['spam', 'offer', 'free', '']",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', '']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "ROR",
      "lineno": 11,
      "original_line": "is_too_long = len(article) > 2000",
      "mutated_line": "is_too_long = len(article) >= 2000",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) >= 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "ROR",
      "lineno": 11,
      "original_line": "is_too_long = len(article) > 2000",
      "mutated_line": "is_too_long = len(article) <= 2000",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) <= 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "ROR",
      "lineno": 11,
      "original_line": "is_too_long = len(article) > 2000",
      "mutated_line": "is_too_long = len(article) != 2000",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) != 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "LCR",
      "lineno": 13,
      "original_line": "if contains_spam_words or contains_spam_patterns or is_too_long:",
      "mutated_line": "classification.append('spam')",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2000\n        if contains_spam_words and contains_spam_patterns and is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "spam_patterns = [re.compile(r'\\b\\d{4}\\b')]",
      "mutated_line": "spam_patterns = [re.compile('')]",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "is_too_long = len(article) > 2000",
      "mutated_line": "is_too_long = len(article) > 2001",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2001\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "is_too_long = len(article) > 2000",
      "mutated_line": "is_too_long = len(article) > 1999",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 1999\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "is_too_long = len(article) > 2000",
      "mutated_line": "is_too_long = len(article) > 0",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 0\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "is_too_long = len(article) > 2000",
      "mutated_line": "is_too_long = len(article) > 1",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 1\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "is_too_long = len(article) > 2000",
      "mutated_line": "is_too_long = len(article) > -2000",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > -2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "ROR",
      "lineno": 9,
      "original_line": "contains_spam_words = any(word in article.lower() for word in spam_words)",
      "mutated_line": "contains_spam_words = any((word not in article.lower() for word in spam_words))",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word not in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 14,
      "original_line": "classification.append(\"spam\")",
      "mutated_line": "classification.append('')",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('')\n        else:\n            classification.append('ham')\n    return classification"
    },
    {
      "operator": "CRP",
      "lineno": 16,
      "original_line": "classification.append(\"ham\")",
      "mutated_line": "classification.append('')",
      "code": "import re\n\ndef classify_articles(articles):\n    classification = []\n    spam_words = ['spam', 'offer', 'free', 'amazing']\n    spam_patterns = [re.compile('\\\\b\\\\d{4}\\\\b')]\n    for article in articles:\n        contains_spam_words = any((word in article.lower() for word in spam_words))\n        contains_spam_patterns = any((pattern.search(article) for pattern in spam_patterns))\n        is_too_long = len(article) > 2000\n        if contains_spam_words or contains_spam_patterns or is_too_long:\n            classification.append('spam')\n        else:\n            classification.append('')\n    return classification"
    }
  ]
}