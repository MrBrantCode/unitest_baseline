{
  "task_id": "cf_55440",
  "entry_point": "gradient_descent",
  "mutant_count": 20,
  "mutants": [
    {
      "operator": "AOR",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 / (x - 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 / (x - 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "AOR",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 + (x - 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 + (x - 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "AOR",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 ** (x - 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 ** (x - 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "AOR",
      "lineno": 5,
      "original_line": "x = x - learning_rate * grad",
      "mutated_line": "x = x + learning_rate * grad",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - 5)\n        x = x + learning_rate * grad\n    return x"
    },
    {
      "operator": "AOR",
      "lineno": 5,
      "original_line": "x = x - learning_rate * grad",
      "mutated_line": "x = x * (learning_rate * grad)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - 5)\n        x = x * (learning_rate * grad)\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 3 * (x - 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 3 * (x - 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 1 * (x - 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 1 * (x - 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 0 * (x - 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 0 * (x - 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 1 * (x - 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 1 * (x - 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = -2 * (x - 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = -2 * (x - 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "AOR",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 * (x + 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x + 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "AOR",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 * (x * 5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x * 5)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "AOR",
      "lineno": 5,
      "original_line": "x = x - learning_rate * grad",
      "mutated_line": "x = x - learning_rate / grad",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - 5)\n        x = x - learning_rate / grad\n    return x"
    },
    {
      "operator": "AOR",
      "lineno": 5,
      "original_line": "x = x - learning_rate * grad",
      "mutated_line": "x = x - (learning_rate + grad)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - 5)\n        x = x - (learning_rate + grad)\n    return x"
    },
    {
      "operator": "AOR",
      "lineno": 5,
      "original_line": "x = x - learning_rate * grad",
      "mutated_line": "x = x - learning_rate ** grad",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - 5)\n        x = x - learning_rate ** grad\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 * (x - 6)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - 6)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 * (x - 4)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - 4)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 * (x - 0)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - 0)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 * (x - 1)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - 1)\n        x = x - learning_rate * grad\n    return x"
    },
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "grad = 2 * (x - 5)",
      "mutated_line": "grad = 2 * (x - -5)",
      "code": "def gradient_descent(start_x, learning_rate, iteration):\n    x = start_x\n    for i in range(iteration):\n        grad = 2 * (x - -5)\n        x = x - learning_rate * grad\n    return x"
    }
  ]
}