{
  "task_id": "cf_6734",
  "entry_point": "generate_summary",
  "mutant_count": 22,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "ASR",
      "lineno": 27,
      "original_line": "word_freq[token] += 1",
      "mutated_line": "word_freq[token] -= 1",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] -= 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "ROR",
      "lineno": 42,
      "original_line": "if len(summary_sentences) == 0:",
      "mutated_line": "return 'No summary could be generated.'",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) != 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 18,
      "original_line": "tokens = re.findall(r'\\b\\w+\\b', text.lower())",
      "mutated_line": "stopwords = set(['the', 'and', 'in', 'etc.'])",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "word_freq[token] += 1",
      "mutated_line": "word_freq[token] += 2",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 2\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "word_freq[token] += 1",
      "mutated_line": "word_freq[token] += 0",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 0\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "word_freq[token] += 1",
      "mutated_line": "word_freq[token] += 0",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 0\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "word_freq[token] += 1",
      "mutated_line": "word_freq[token] += -1",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += -1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)",
      "mutated_line": "sentences = re.split('', text)",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 42,
      "original_line": "if len(summary_sentences) == 0:",
      "mutated_line": "return 'No summary could be generated.'",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 1:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 42,
      "original_line": "if len(summary_sentences) == 0:",
      "mutated_line": "return 'No summary could be generated.'",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == -1:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 42,
      "original_line": "if len(summary_sentences) == 0:",
      "mutated_line": "return 'No summary could be generated.'",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 1:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 43,
      "original_line": "return \"No summary could be generated.\"",
      "mutated_line": "return ''",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return ''\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "stopwords = set(['the', 'and', 'in', 'etc.']) # Add more stopwords as needed",
      "mutated_line": "stopwords = set(['', 'and', 'in', 'etc.'])",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "stopwords = set(['the', 'and', 'in', 'etc.']) # Add more stopwords as needed",
      "mutated_line": "stopwords = set(['the', '', 'in', 'etc.'])",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', '', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "stopwords = set(['the', 'and', 'in', 'etc.']) # Add more stopwords as needed",
      "mutated_line": "stopwords = set(['the', 'and', '', 'etc.'])",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', '', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 21,
      "original_line": "stopwords = set(['the', 'and', 'in', 'etc.']) # Add more stopwords as needed",
      "mutated_line": "stopwords = set(['the', 'and', 'in', ''])",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', ''])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "ROR",
      "lineno": 22,
      "original_line": "filtered_tokens = [token for token in tokens if token not in stopwords]",
      "mutated_line": "filtered_tokens = [token for token in tokens if token in stopwords]",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 35,
      "original_line": "for word in re.findall(r'\\b\\w+\\b', sentence.lower()):",
      "mutated_line": "for word in re.findall('', sentence.lower()):",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "ROR",
      "lineno": 36,
      "original_line": "if word in word_freq:",
      "mutated_line": "if word not in word_freq:",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word not in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "ASR",
      "lineno": 37,
      "original_line": "sentence_scores[sentence] += word_freq[word]",
      "mutated_line": "sentence_scores[sentence] -= word_freq[word]",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] -= word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ' '.join(summary_sentences)\n    return summary"
    },
    {
      "operator": "CRP",
      "lineno": 46,
      "original_line": "summary = ' '.join(summary_sentences)",
      "mutated_line": "summary = ''.join(summary_sentences)",
      "code": "import re\nimport heapq\nfrom collections import defaultdict\n\ndef generate_summary(text, max_words):\n    \"\"\"\n    Generate a summary of the input text, limited to the specified number of words.\n    \n    Parameters:\n    text (str): The input text.\n    max_words (int): The maximum number of words in the summary.\n    \n    Returns:\n    str: A string summary of the text, limited to the specified number of words.\n    \"\"\"\n    tokens = re.findall('\\\\b\\\\w+\\\\b', text.lower())\n    stopwords = set(['the', 'and', 'in', 'etc.'])\n    filtered_tokens = [token for token in tokens if token not in stopwords]\n    word_freq = defaultdict(int)\n    for token in filtered_tokens:\n        word_freq[token] += 1\n    sentences = re.split('(?<!\\\\w\\\\.\\\\w.)(?<![A-Z][a-z]\\\\.)(?<=\\\\.|\\\\?)\\\\s', text)\n    sentence_scores = defaultdict(int)\n    for sentence in sentences:\n        for word in re.findall('\\\\b\\\\w+\\\\b', sentence.lower()):\n            if word in word_freq:\n                sentence_scores[sentence] += word_freq[word]\n    summary_sentences = heapq.nlargest(max_words, sentence_scores, key=sentence_scores.get)\n    if len(summary_sentences) == 0:\n        return 'No summary could be generated.'\n    summary = ''.join(summary_sentences)\n    return summary"
    }
  ]
}