{
  "task_id": "cf_29917",
  "entry_point": "entrance",
  "mutant_count": 43,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 3,
      "original_line": "it = 0",
      "mutated_line": "it = 1",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 1\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 3,
      "original_line": "it = 0",
      "mutated_line": "it = -1",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = -1\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 3,
      "original_line": "it = 0",
      "mutated_line": "it = 1",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 1\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "ROR",
      "lineno": 4,
      "original_line": "while it < max_iterations:",
      "mutated_line": "while it <= max_iterations:",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it <= max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "ROR",
      "lineno": 4,
      "original_line": "while it < max_iterations:",
      "mutated_line": "while it >= max_iterations:",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it >= max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "ROR",
      "lineno": 4,
      "original_line": "while it < max_iterations:",
      "mutated_line": "while it != max_iterations:",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it != max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "ASR",
      "lineno": 7,
      "original_line": "xk -= learning_rate * gradient",
      "mutated_line": "xk += learning_rate * gradient",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk += learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "ASR",
      "lineno": 9,
      "original_line": "it += 1",
      "mutated_line": "it -= 1",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it -= 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "ROR",
      "lineno": 10,
      "original_line": "if it == max_iterations:",
      "mutated_line": "if it != max_iterations:",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it != max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) * 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) * 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) // 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) // 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "xk -= learning_rate * gradient",
      "mutated_line": "xk -= learning_rate / gradient",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate / gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "xk -= learning_rate * gradient",
      "mutated_line": "xk -= learning_rate + gradient",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate + gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "AOR",
      "lineno": 7,
      "original_line": "xk -= learning_rate * gradient",
      "mutated_line": "xk -= learning_rate ** gradient",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate ** gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 9,
      "original_line": "it += 1",
      "mutated_line": "it += 2",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 2\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 9,
      "original_line": "it += 1",
      "mutated_line": "it += 0",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 0\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 9,
      "original_line": "it += 1",
      "mutated_line": "it += 0",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 0\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 9,
      "original_line": "it += 1",
      "mutated_line": "it += -1",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += -1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "UOI",
      "lineno": 5,
      "original_line": "xk = xks[-1]",
      "mutated_line": "xk = xks[+1]",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[+1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 0.0001) + objective_function(xk)) / 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) + objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = objective_function(xk + 0.0001) * objective_function(xk) / 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = objective_function(xk + 0.0001) * objective_function(xk) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 1.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 1.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / -0.9999",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / -0.9999\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 1",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 1\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / -0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / -0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "print(\"Maximum number of iterations reached\")",
      "mutated_line": "print('')",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "UOI",
      "lineno": 12,
      "original_line": "return xks[-1], it, xks",
      "mutated_line": "return (xks[+1], it, xks)",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[+1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "xk = xks[-1]",
      "mutated_line": "xk = xks[-2]",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-2]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "xk = xks[-1]",
      "mutated_line": "xk = xks[-0]",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-0]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "xk = xks[-1]",
      "mutated_line": "xk = xks[-0]",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-0]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "xk = xks[-1]",
      "mutated_line": "xk = xks[--1]",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[--1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 12,
      "original_line": "return xks[-1], it, xks",
      "mutated_line": "return (xks[-2], it, xks)",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-2], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 12,
      "original_line": "return xks[-1], it, xks",
      "mutated_line": "return (xks[-0], it, xks)",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-0], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 12,
      "original_line": "return xks[-1], it, xks",
      "mutated_line": "return (xks[-0], it, xks)",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-0], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 12,
      "original_line": "return xks[-1], it, xks",
      "mutated_line": "return (xks[--1], it, xks)",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[--1], it, xks)"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk - 0.0001) - objective_function(xk)) / 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk - 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "AOR",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk * 0.0001) - objective_function(xk)) / 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk * 0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 1.0001) - objective_function(xk)) / 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 1.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + -0.9999) - objective_function(xk)) / 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + -0.9999) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 0) - objective_function(xk)) / 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 0) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + 1) - objective_function(xk)) / 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + 1) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "gradient = (objective_function(xk + 0.0001) - objective_function(xk)) / 0.0001  # Approximate gradient",
      "mutated_line": "gradient = (objective_function(xk + -0.0001) - objective_function(xk)) / 0.0001",
      "code": "def entrance(x0, learning_rate, max_iterations, objective_function):\n    xks = [x0]\n    it = 0\n    while it < max_iterations:\n        xk = xks[-1]\n        gradient = (objective_function(xk + -0.0001) - objective_function(xk)) / 0.0001\n        xk -= learning_rate * gradient\n        xks.append(xk)\n        it += 1\n    if it == max_iterations:\n        print('Maximum number of iterations reached')\n    return (xks[-1], it, xks)"
    }
  ]
}