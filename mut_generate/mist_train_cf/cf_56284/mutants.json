{
  "task_id": "cf_56284",
  "entry_point": "url_details",
  "mutant_count": 20,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "ROR",
      "lineno": 22,
      "original_line": "if re.match(regex, url) is None:",
      "mutated_line": "print('Invalid URL')",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is not None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 14,
      "original_line": "r'^(?:http|ftp)s?://'  # http:// or https://",
      "mutated_line": "regex = re.compile('', re.IGNORECASE)",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 34,
      "original_line": "print(\"Protocol: \", protocol)",
      "mutated_line": "print('Path: ', path)",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 35,
      "original_line": "print(\"Domain: \", domain)",
      "mutated_line": "print('Path: ', path)",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 36,
      "original_line": "print(\"Path: \", path)",
      "mutated_line": "print('', path)",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 41,
      "original_line": "print(\"Parameters: \")",
      "mutated_line": "for (key, value) in params.items():",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 51,
      "original_line": "print(\"\\nFrequency of each letter in Domain: \")",
      "mutated_line": "for (key, value) in letters_frequency.items():",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 23,
      "original_line": "print(\"Invalid URL\")",
      "mutated_line": "print('')",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 43,
      "original_line": "print(key, \": \", value)",
      "mutated_line": "print(key, '', value)",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, '', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "AOR",
      "lineno": 49,
      "original_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 1",
      "mutated_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) - 1",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) - 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "AOR",
      "lineno": 49,
      "original_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 1",
      "mutated_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) * 1",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) * 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 53,
      "original_line": "print(key, \": \", value)",
      "mutated_line": "print(key, '', value)",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, '', value)"
    },
    {
      "operator": "CRP",
      "lineno": 49,
      "original_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 1",
      "mutated_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 2",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 2\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 49,
      "original_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 1",
      "mutated_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 0",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 0\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 49,
      "original_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 1",
      "mutated_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 0",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + 0\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 49,
      "original_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 1",
      "mutated_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + -1",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 0) + -1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 49,
      "original_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 1",
      "mutated_line": "letters_frequency[letter] = letters_frequency.get(letter, 1) + 1",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 1) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 49,
      "original_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 1",
      "mutated_line": "letters_frequency[letter] = letters_frequency.get(letter, -1) + 1",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, -1) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    },
    {
      "operator": "CRP",
      "lineno": 49,
      "original_line": "letters_frequency[letter] = letters_frequency.get(letter, 0) + 1",
      "mutated_line": "letters_frequency[letter] = letters_frequency.get(letter, 1) + 1",
      "code": "import re\nfrom urllib.parse import urlparse, parse_qs\n\ndef url_details(url):\n    \"\"\"\n    Function to extract and print the URL details\n\n    Args:\n    url (str): the URL to be analyzed\n    \"\"\"\n    regex = re.compile('^(?:http|ftp)s?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?)|localhost|\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}|\\\\[?[A-F0-9]*:[A-F0-9:]+\\\\]?)(?::\\\\d+)?(?:/?|[/?]\\\\S+)$', re.IGNORECASE)\n    if re.match(regex, url) is None:\n        print('Invalid URL')\n        return\n    parsed_url = urlparse(url)\n    protocol = parsed_url.scheme\n    domain = parsed_url.netloc\n    path = parsed_url.path\n    print('Protocol: ', protocol)\n    print('Domain: ', domain)\n    print('Path: ', path)\n    params = parse_qs(parsed_url.query)\n    print('Parameters: ')\n    for (key, value) in params.items():\n        print(key, ': ', value)\n    letters_frequency = {}\n    for letter in domain:\n        if letter.isalpha():\n            letters_frequency[letter] = letters_frequency.get(letter, 1) + 1\n    print('\\nFrequency of each letter in Domain: ')\n    for (key, value) in letters_frequency.items():\n        print(key, ': ', value)"
    }
  ]
}