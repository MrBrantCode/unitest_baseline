{
  "task_id": "cf_64008",
  "entry_point": "manage_data_skew",
  "mutant_count": 5,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 2,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "def manage_data_skew(data_chunks, num_nodes):\n    \"\"\"\"\"\"\n    chunks_per_node = len(data_chunks) // num_nodes\n    assigned_chunks = {node_id: [] for node_id in range(num_nodes)}\n    for (i, chunk) in enumerate(data_chunks):\n        node_id = i % num_nodes\n        assigned_chunks[node_id].append(chunk)\n    return assigned_chunks"
    },
    {
      "operator": "AOR",
      "lineno": 13,
      "original_line": "chunks_per_node = len(data_chunks) // num_nodes",
      "mutated_line": "chunks_per_node = len(data_chunks) / num_nodes",
      "code": "def manage_data_skew(data_chunks, num_nodes):\n    \"\"\"\n    Mitigate data skew in a Hadoop ecosystem by distributing data chunks evenly across nodes.\n\n    Args:\n        data_chunks (list): List of data chunks to be distributed.\n        num_nodes (int): Number of nodes in the cluster.\n\n    Returns:\n        dict: Dictionary where keys are node IDs and values are lists of data chunks assigned to each node.\n    \"\"\"\n    chunks_per_node = len(data_chunks) / num_nodes\n    assigned_chunks = {node_id: [] for node_id in range(num_nodes)}\n    for (i, chunk) in enumerate(data_chunks):\n        node_id = i % num_nodes\n        assigned_chunks[node_id].append(chunk)\n    return assigned_chunks"
    },
    {
      "operator": "AOR",
      "lineno": 13,
      "original_line": "chunks_per_node = len(data_chunks) // num_nodes",
      "mutated_line": "chunks_per_node = len(data_chunks) * num_nodes",
      "code": "def manage_data_skew(data_chunks, num_nodes):\n    \"\"\"\n    Mitigate data skew in a Hadoop ecosystem by distributing data chunks evenly across nodes.\n\n    Args:\n        data_chunks (list): List of data chunks to be distributed.\n        num_nodes (int): Number of nodes in the cluster.\n\n    Returns:\n        dict: Dictionary where keys are node IDs and values are lists of data chunks assigned to each node.\n    \"\"\"\n    chunks_per_node = len(data_chunks) * num_nodes\n    assigned_chunks = {node_id: [] for node_id in range(num_nodes)}\n    for (i, chunk) in enumerate(data_chunks):\n        node_id = i % num_nodes\n        assigned_chunks[node_id].append(chunk)\n    return assigned_chunks"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "node_id = i % num_nodes",
      "mutated_line": "node_id = i * num_nodes",
      "code": "def manage_data_skew(data_chunks, num_nodes):\n    \"\"\"\n    Mitigate data skew in a Hadoop ecosystem by distributing data chunks evenly across nodes.\n\n    Args:\n        data_chunks (list): List of data chunks to be distributed.\n        num_nodes (int): Number of nodes in the cluster.\n\n    Returns:\n        dict: Dictionary where keys are node IDs and values are lists of data chunks assigned to each node.\n    \"\"\"\n    chunks_per_node = len(data_chunks) // num_nodes\n    assigned_chunks = {node_id: [] for node_id in range(num_nodes)}\n    for (i, chunk) in enumerate(data_chunks):\n        node_id = i * num_nodes\n        assigned_chunks[node_id].append(chunk)\n    return assigned_chunks"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "node_id = i % num_nodes",
      "mutated_line": "node_id = i + num_nodes",
      "code": "def manage_data_skew(data_chunks, num_nodes):\n    \"\"\"\n    Mitigate data skew in a Hadoop ecosystem by distributing data chunks evenly across nodes.\n\n    Args:\n        data_chunks (list): List of data chunks to be distributed.\n        num_nodes (int): Number of nodes in the cluster.\n\n    Returns:\n        dict: Dictionary where keys are node IDs and values are lists of data chunks assigned to each node.\n    \"\"\"\n    chunks_per_node = len(data_chunks) // num_nodes\n    assigned_chunks = {node_id: [] for node_id in range(num_nodes)}\n    for (i, chunk) in enumerate(data_chunks):\n        node_id = i + num_nodes\n        assigned_chunks[node_id].append(chunk)\n    return assigned_chunks"
    }
  ]
}