{
  "task_id": "cf_50860",
  "entry_point": "ridge_regression_gradient",
  "mutant_count": 8,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "import numpy as np\n\ndef ridge_regression_gradient(X, w, y, lambda_val):\n    \"\"\"\"\"\"\n    return X.T @ (X @ w - y) + lambda_val * w"
    },
    {
      "operator": "AOR",
      "lineno": 17,
      "original_line": "return X.T @ (X @ w - y) + lambda_val * w",
      "mutated_line": "return X.T @ (X @ w - y) - lambda_val * w",
      "code": "import numpy as np\n\ndef ridge_regression_gradient(X, w, y, lambda_val):\n    \"\"\"\n    This function calculates the gradient of the function \n    0.5 * ||Xw-y||^2 + 0.5 * lambda_val * ||w||^2 with respect to w.\n\n    Parameters:\n    X (numpy array): input data matrix\n    w (numpy array): weight vector\n    y (numpy array): target vector\n    lambda_val (float): non-negative regularization parameter\n\n    Returns:\n    numpy array: the gradient vector\n    \"\"\"\n    return X.T @ (X @ w - y) - lambda_val * w"
    },
    {
      "operator": "AOR",
      "lineno": 17,
      "original_line": "return X.T @ (X @ w - y) + lambda_val * w",
      "mutated_line": "return X.T @ (X @ w - y) * (lambda_val * w)",
      "code": "import numpy as np\n\ndef ridge_regression_gradient(X, w, y, lambda_val):\n    \"\"\"\n    This function calculates the gradient of the function \n    0.5 * ||Xw-y||^2 + 0.5 * lambda_val * ||w||^2 with respect to w.\n\n    Parameters:\n    X (numpy array): input data matrix\n    w (numpy array): weight vector\n    y (numpy array): target vector\n    lambda_val (float): non-negative regularization parameter\n\n    Returns:\n    numpy array: the gradient vector\n    \"\"\"\n    return X.T @ (X @ w - y) * (lambda_val * w)"
    },
    {
      "operator": "AOR",
      "lineno": 17,
      "original_line": "return X.T @ (X @ w - y) + lambda_val * w",
      "mutated_line": "return X.T @ (X @ w - y) + lambda_val / w",
      "code": "import numpy as np\n\ndef ridge_regression_gradient(X, w, y, lambda_val):\n    \"\"\"\n    This function calculates the gradient of the function \n    0.5 * ||Xw-y||^2 + 0.5 * lambda_val * ||w||^2 with respect to w.\n\n    Parameters:\n    X (numpy array): input data matrix\n    w (numpy array): weight vector\n    y (numpy array): target vector\n    lambda_val (float): non-negative regularization parameter\n\n    Returns:\n    numpy array: the gradient vector\n    \"\"\"\n    return X.T @ (X @ w - y) + lambda_val / w"
    },
    {
      "operator": "AOR",
      "lineno": 17,
      "original_line": "return X.T @ (X @ w - y) + lambda_val * w",
      "mutated_line": "return X.T @ (X @ w - y) + (lambda_val + w)",
      "code": "import numpy as np\n\ndef ridge_regression_gradient(X, w, y, lambda_val):\n    \"\"\"\n    This function calculates the gradient of the function \n    0.5 * ||Xw-y||^2 + 0.5 * lambda_val * ||w||^2 with respect to w.\n\n    Parameters:\n    X (numpy array): input data matrix\n    w (numpy array): weight vector\n    y (numpy array): target vector\n    lambda_val (float): non-negative regularization parameter\n\n    Returns:\n    numpy array: the gradient vector\n    \"\"\"\n    return X.T @ (X @ w - y) + (lambda_val + w)"
    },
    {
      "operator": "AOR",
      "lineno": 17,
      "original_line": "return X.T @ (X @ w - y) + lambda_val * w",
      "mutated_line": "return X.T @ (X @ w - y) + lambda_val ** w",
      "code": "import numpy as np\n\ndef ridge_regression_gradient(X, w, y, lambda_val):\n    \"\"\"\n    This function calculates the gradient of the function \n    0.5 * ||Xw-y||^2 + 0.5 * lambda_val * ||w||^2 with respect to w.\n\n    Parameters:\n    X (numpy array): input data matrix\n    w (numpy array): weight vector\n    y (numpy array): target vector\n    lambda_val (float): non-negative regularization parameter\n\n    Returns:\n    numpy array: the gradient vector\n    \"\"\"\n    return X.T @ (X @ w - y) + lambda_val ** w"
    },
    {
      "operator": "AOR",
      "lineno": 17,
      "original_line": "return X.T @ (X @ w - y) + lambda_val * w",
      "mutated_line": "return X.T @ (X @ w + y) + lambda_val * w",
      "code": "import numpy as np\n\ndef ridge_regression_gradient(X, w, y, lambda_val):\n    \"\"\"\n    This function calculates the gradient of the function \n    0.5 * ||Xw-y||^2 + 0.5 * lambda_val * ||w||^2 with respect to w.\n\n    Parameters:\n    X (numpy array): input data matrix\n    w (numpy array): weight vector\n    y (numpy array): target vector\n    lambda_val (float): non-negative regularization parameter\n\n    Returns:\n    numpy array: the gradient vector\n    \"\"\"\n    return X.T @ (X @ w + y) + lambda_val * w"
    },
    {
      "operator": "AOR",
      "lineno": 17,
      "original_line": "return X.T @ (X @ w - y) + lambda_val * w",
      "mutated_line": "return X.T @ (X @ w * y) + lambda_val * w",
      "code": "import numpy as np\n\ndef ridge_regression_gradient(X, w, y, lambda_val):\n    \"\"\"\n    This function calculates the gradient of the function \n    0.5 * ||Xw-y||^2 + 0.5 * lambda_val * ||w||^2 with respect to w.\n\n    Parameters:\n    X (numpy array): input data matrix\n    w (numpy array): weight vector\n    y (numpy array): target vector\n    lambda_val (float): non-negative regularization parameter\n\n    Returns:\n    numpy array: the gradient vector\n    \"\"\"\n    return X.T @ (X @ w * y) + lambda_val * w"
    }
  ]
}