{
  "task_id": "cf_17540",
  "entry_point": "tokenize",
  "mutant_count": 15,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "sentence = re.sub(r'[^\\w\\s]', '', sentence)",
      "mutated_line": "sentence = re.sub('', '', sentence)",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 5,
      "original_line": "sentence = re.sub(r'[^\\w\\s]', '', sentence)",
      "mutated_line": "sentence = re.sub('[^\\\\w\\\\s]', 'MUTATED', sentence)",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', 'MUTATED', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', '', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', '', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', '', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', '', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', 'is', '', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', '', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', 'is', 'a', '', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', '', 'am', 'an', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', 'is', 'a', 'I', '', 'an', 'are', 'it', 'in', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', '', 'an', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', '', 'are', 'it', 'in', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', 'am', '', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', '', 'it', 'in', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', '', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', '', 'in', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', '', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', '', 'to', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', '', 'to', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', '', 'of']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', '', 'of']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "CRP",
      "lineno": 11,
      "original_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']",
      "mutated_line": "stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', '']",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', '']\n    words = [word for word in words if word.lower() not in stop_words]\n    return words"
    },
    {
      "operator": "ROR",
      "lineno": 12,
      "original_line": "words = [word for word in words if word.lower() not in stop_words]",
      "mutated_line": "words = [word for word in words if word.lower() in stop_words]",
      "code": "import re\n\ndef tokenize(sentence):\n    sentence = re.sub('[^\\\\w\\\\s]', '', sentence)\n    words = sentence.split()\n    stop_words = ['the', 'and', 'is', 'a', 'I', 'am', 'an', 'are', 'it', 'in', 'to', 'of']\n    words = [word for word in words if word.lower() in stop_words]\n    return words"
    }
  ]
}