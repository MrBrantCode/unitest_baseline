{
  "task_id": "cf_55325",
  "entry_point": "softmax_temperature_entropy",
  "mutant_count": 9,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 4,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "import numpy as np\n\ndef softmax_temperature_entropy(scores, temperature):\n    \"\"\"\"\"\"\n    exp_scores = np.exp(np.array(scores) / temperature)\n    softmax_output = exp_scores / np.sum(exp_scores)\n    entropy = -np.sum(softmax_output * np.log(softmax_output))\n    return (softmax_output, entropy)"
    },
    {
      "operator": "AOR",
      "lineno": 17,
      "original_line": "softmax_output = exp_scores / np.sum(exp_scores)",
      "mutated_line": "softmax_output = exp_scores * np.sum(exp_scores)",
      "code": "import numpy as np\n\ndef softmax_temperature_entropy(scores, temperature):\n    \"\"\"\n    Calculate the softmax output and Shannon entropy for a given set of raw scores and temperature parameter.\n\n    Parameters:\n    scores (list): A list of raw scores.\n    temperature (float): The temperature parameter.\n\n    Returns:\n    tuple: A tuple containing the softmax output and the Shannon entropy.\n    \"\"\"\n    exp_scores = np.exp(np.array(scores) / temperature)\n    softmax_output = exp_scores * np.sum(exp_scores)\n    entropy = -np.sum(softmax_output * np.log(softmax_output))\n    return (softmax_output, entropy)"
    },
    {
      "operator": "AOR",
      "lineno": 17,
      "original_line": "softmax_output = exp_scores / np.sum(exp_scores)",
      "mutated_line": "softmax_output = exp_scores // np.sum(exp_scores)",
      "code": "import numpy as np\n\ndef softmax_temperature_entropy(scores, temperature):\n    \"\"\"\n    Calculate the softmax output and Shannon entropy for a given set of raw scores and temperature parameter.\n\n    Parameters:\n    scores (list): A list of raw scores.\n    temperature (float): The temperature parameter.\n\n    Returns:\n    tuple: A tuple containing the softmax output and the Shannon entropy.\n    \"\"\"\n    exp_scores = np.exp(np.array(scores) / temperature)\n    softmax_output = exp_scores // np.sum(exp_scores)\n    entropy = -np.sum(softmax_output * np.log(softmax_output))\n    return (softmax_output, entropy)"
    },
    {
      "operator": "UOI",
      "lineno": 20,
      "original_line": "entropy = -np.sum(softmax_output * np.log(softmax_output))",
      "mutated_line": "return (softmax_output, entropy)",
      "code": "import numpy as np\n\ndef softmax_temperature_entropy(scores, temperature):\n    \"\"\"\n    Calculate the softmax output and Shannon entropy for a given set of raw scores and temperature parameter.\n\n    Parameters:\n    scores (list): A list of raw scores.\n    temperature (float): The temperature parameter.\n\n    Returns:\n    tuple: A tuple containing the softmax output and the Shannon entropy.\n    \"\"\"\n    exp_scores = np.exp(np.array(scores) / temperature)\n    softmax_output = exp_scores / np.sum(exp_scores)\n    entropy = +np.sum(softmax_output * np.log(softmax_output))\n    return (softmax_output, entropy)"
    },
    {
      "operator": "AOR",
      "lineno": 16,
      "original_line": "exp_scores = np.exp(np.array(scores) / temperature)",
      "mutated_line": "exp_scores = np.exp(np.array(scores) * temperature)",
      "code": "import numpy as np\n\ndef softmax_temperature_entropy(scores, temperature):\n    \"\"\"\n    Calculate the softmax output and Shannon entropy for a given set of raw scores and temperature parameter.\n\n    Parameters:\n    scores (list): A list of raw scores.\n    temperature (float): The temperature parameter.\n\n    Returns:\n    tuple: A tuple containing the softmax output and the Shannon entropy.\n    \"\"\"\n    exp_scores = np.exp(np.array(scores) * temperature)\n    softmax_output = exp_scores / np.sum(exp_scores)\n    entropy = -np.sum(softmax_output * np.log(softmax_output))\n    return (softmax_output, entropy)"
    },
    {
      "operator": "AOR",
      "lineno": 16,
      "original_line": "exp_scores = np.exp(np.array(scores) / temperature)",
      "mutated_line": "exp_scores = np.exp(np.array(scores) // temperature)",
      "code": "import numpy as np\n\ndef softmax_temperature_entropy(scores, temperature):\n    \"\"\"\n    Calculate the softmax output and Shannon entropy for a given set of raw scores and temperature parameter.\n\n    Parameters:\n    scores (list): A list of raw scores.\n    temperature (float): The temperature parameter.\n\n    Returns:\n    tuple: A tuple containing the softmax output and the Shannon entropy.\n    \"\"\"\n    exp_scores = np.exp(np.array(scores) // temperature)\n    softmax_output = exp_scores / np.sum(exp_scores)\n    entropy = -np.sum(softmax_output * np.log(softmax_output))\n    return (softmax_output, entropy)"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "entropy = -np.sum(softmax_output * np.log(softmax_output))",
      "mutated_line": "return (softmax_output, entropy)",
      "code": "import numpy as np\n\ndef softmax_temperature_entropy(scores, temperature):\n    \"\"\"\n    Calculate the softmax output and Shannon entropy for a given set of raw scores and temperature parameter.\n\n    Parameters:\n    scores (list): A list of raw scores.\n    temperature (float): The temperature parameter.\n\n    Returns:\n    tuple: A tuple containing the softmax output and the Shannon entropy.\n    \"\"\"\n    exp_scores = np.exp(np.array(scores) / temperature)\n    softmax_output = exp_scores / np.sum(exp_scores)\n    entropy = -np.sum(softmax_output / np.log(softmax_output))\n    return (softmax_output, entropy)"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "entropy = -np.sum(softmax_output * np.log(softmax_output))",
      "mutated_line": "return (softmax_output, entropy)",
      "code": "import numpy as np\n\ndef softmax_temperature_entropy(scores, temperature):\n    \"\"\"\n    Calculate the softmax output and Shannon entropy for a given set of raw scores and temperature parameter.\n\n    Parameters:\n    scores (list): A list of raw scores.\n    temperature (float): The temperature parameter.\n\n    Returns:\n    tuple: A tuple containing the softmax output and the Shannon entropy.\n    \"\"\"\n    exp_scores = np.exp(np.array(scores) / temperature)\n    softmax_output = exp_scores / np.sum(exp_scores)\n    entropy = -np.sum(softmax_output + np.log(softmax_output))\n    return (softmax_output, entropy)"
    },
    {
      "operator": "AOR",
      "lineno": 20,
      "original_line": "entropy = -np.sum(softmax_output * np.log(softmax_output))",
      "mutated_line": "return (softmax_output, entropy)",
      "code": "import numpy as np\n\ndef softmax_temperature_entropy(scores, temperature):\n    \"\"\"\n    Calculate the softmax output and Shannon entropy for a given set of raw scores and temperature parameter.\n\n    Parameters:\n    scores (list): A list of raw scores.\n    temperature (float): The temperature parameter.\n\n    Returns:\n    tuple: A tuple containing the softmax output and the Shannon entropy.\n    \"\"\"\n    exp_scores = np.exp(np.array(scores) / temperature)\n    softmax_output = exp_scores / np.sum(exp_scores)\n    entropy = -np.sum(softmax_output ** np.log(softmax_output))\n    return (softmax_output, entropy)"
    }
  ]
}