{
  "task_id": "cf_65048",
  "entry_point": "store_large_data",
  "mutant_count": 17,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 2,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "UOI",
      "lineno": 21,
      "original_line": "num_chunks = -(-len(data) // max_record_size)  # Ceiling division",
      "mutated_line": "num_chunks = +(-len(data) // max_record_size)",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = +(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "num_chunks = -(-len(data) // max_record_size)  # Ceiling division",
      "mutated_line": "num_chunks = -(-len(data) / max_record_size)",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) / max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 21,
      "original_line": "num_chunks = -(-len(data) // max_record_size)  # Ceiling division",
      "mutated_line": "num_chunks = -(-len(data) * max_record_size)",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) * max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 25,
      "original_line": "start = i * max_record_size",
      "mutated_line": "start = i / max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i / max_record_size\n        end = (i + 1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 25,
      "original_line": "start = i * max_record_size",
      "mutated_line": "start = i + max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i + max_record_size\n        end = (i + 1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 25,
      "original_line": "start = i * max_record_size",
      "mutated_line": "start = i ** max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i ** max_record_size\n        end = (i + 1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 26,
      "original_line": "end = (i + 1) * max_record_size",
      "mutated_line": "end = (i + 1) / max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 1) / max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 26,
      "original_line": "end = (i + 1) * max_record_size",
      "mutated_line": "end = i + 1 + max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = i + 1 + max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 26,
      "original_line": "end = (i + 1) * max_record_size",
      "mutated_line": "end = (i + 1) ** max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 1) ** max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "UOI",
      "lineno": 21,
      "original_line": "num_chunks = -(-len(data) // max_record_size)  # Ceiling division",
      "mutated_line": "num_chunks = -(+len(data) // max_record_size)",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(+len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 26,
      "original_line": "end = (i + 1) * max_record_size",
      "mutated_line": "end = (i - 1) * max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i - 1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "AOR",
      "lineno": 26,
      "original_line": "end = (i + 1) * max_record_size",
      "mutated_line": "end = i * 1 * max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = i * 1 * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "CRP",
      "lineno": 26,
      "original_line": "end = (i + 1) * max_record_size",
      "mutated_line": "end = (i + 2) * max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 2) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "CRP",
      "lineno": 26,
      "original_line": "end = (i + 1) * max_record_size",
      "mutated_line": "end = (i + 0) * max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 0) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "CRP",
      "lineno": 26,
      "original_line": "end = (i + 1) * max_record_size",
      "mutated_line": "end = (i + 0) * max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + 0) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    },
    {
      "operator": "CRP",
      "lineno": 26,
      "original_line": "end = (i + 1) * max_record_size",
      "mutated_line": "end = (i + -1) * max_record_size",
      "code": "def store_large_data(data, max_record_size):\n    \"\"\"\n    Break down large data into chunks that fit within the max_record_size limit,\n    store each chunk in a separate record store, and manage the record stores.\n\n    Args:\n        data (str or bytes): The large amount of data to be stored.\n        max_record_size (int): The maximum size limit for each record store.\n\n    Returns:\n        list: A list of chunks of data that fit within the max_record_size limit.\n    \"\"\"\n    chunks = []\n    if isinstance(data, str):\n        data = data.encode()\n    num_chunks = -(-len(data) // max_record_size)\n    for i in range(num_chunks):\n        start = i * max_record_size\n        end = (i + -1) * max_record_size\n        chunk = data[start:end]\n        chunks.append(chunk)\n    return chunks"
    }
  ]
}