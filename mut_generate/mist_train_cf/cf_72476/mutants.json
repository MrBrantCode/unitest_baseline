{
  "task_id": "cf_72476",
  "entry_point": "ToPMine",
  "mutant_count": 46,
  "mutants": [
    {
      "operator": "CRP",
      "lineno": 2,
      "original_line": "\"\"\"",
      "mutated_line": "\"\"\"\"\"\"",
      "code": "def ToPMine(documents):\n    \"\"\"\"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "threshold = 5",
      "mutated_line": "filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 6\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "threshold = 5",
      "mutated_line": "filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 4\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "threshold = 5",
      "mutated_line": "filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 0\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "threshold = 5",
      "mutated_line": "filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 1\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 30,
      "original_line": "threshold = 5",
      "mutated_line": "filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = -5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ROR",
      "lineno": 46,
      "original_line": "if phrase not in visited:",
      "mutated_line": "if phrase in visited:",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['is', '', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', '', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['is', 'the', '', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', '', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['is', 'the', 'and', '', 'an', 'in', 'on', 'at', 'by', 'with'])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', '', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['is', 'the', 'and', 'a', '', 'in', 'on', 'at', 'by', 'with'])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', '', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['is', 'the', 'and', 'a', 'an', '', 'on', 'at', 'by', 'with'])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', '', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', '', 'at', 'by', 'with'])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', '', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', '', 'by', 'with'])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', '', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', '', 'with'])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', '', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 15,
      "original_line": "stop_words = set([\"is\", \"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"])",
      "mutated_line": "stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', ''])",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', ''])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ROR",
      "lineno": 31,
      "original_line": "filtered_phrases = {phrase: count for phrase, count in phrase_dict.items() if count >= threshold}",
      "mutated_line": "filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count > threshold}",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count > threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ROR",
      "lineno": 31,
      "original_line": "filtered_phrases = {phrase: count for phrase, count in phrase_dict.items() if count >= threshold}",
      "mutated_line": "filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count < threshold}",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count < threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ROR",
      "lineno": 31,
      "original_line": "filtered_phrases = {phrase: count for phrase, count in phrase_dict.items() if count >= threshold}",
      "mutated_line": "filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count == threshold}",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count == threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ROR",
      "lineno": 38,
      "original_line": "if phrase != other_phrase:",
      "mutated_line": "if phrase == other_phrase:",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase == other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ROR",
      "lineno": 16,
      "original_line": "filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]",
      "mutated_line": "filtered_tokens = [[word for word in token if word.lower() in stop_words] for token in tokens]",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "AOR",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i - 1, len(token) + 1):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i - 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "AOR",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i * 1, len(token) + 1):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i * 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "AOR",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + 1, len(token) - 1):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) - 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "AOR",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + 1, len(token) * 1):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) * 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ROR",
      "lineno": 24,
      "original_line": "if phrase in phrase_dict:",
      "mutated_line": "if phrase not in phrase_dict:",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase not in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ASR",
      "lineno": 25,
      "original_line": "phrase_dict[phrase] += 1",
      "mutated_line": "phrase_dict[phrase] -= 1",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] -= 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + 2, len(token) + 1):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 2, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + 0, len(token) + 1):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 0, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + 0, len(token) + 1):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 0, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + -1, len(token) + 1):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + -1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + 1, len(token) + 2):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 2):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + 1, len(token) + 0):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 0):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + 1, len(token) + 0):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 0):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 22,
      "original_line": "for j in range(i + 1, len(token) + 1):",
      "mutated_line": "for j in range(i + 1, len(token) + -1):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + -1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 25,
      "original_line": "phrase_dict[phrase] += 1",
      "mutated_line": "phrase_dict[phrase] += 2",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 2\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 25,
      "original_line": "phrase_dict[phrase] += 1",
      "mutated_line": "phrase_dict[phrase] += 0",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 0\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 25,
      "original_line": "phrase_dict[phrase] += 1",
      "mutated_line": "phrase_dict[phrase] += 0",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 0\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 25,
      "original_line": "phrase_dict[phrase] += 1",
      "mutated_line": "phrase_dict[phrase] += -1",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += -1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "phrase_dict[phrase] = 1",
      "mutated_line": "phrase_dict[phrase] = 2",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 2\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "phrase_dict[phrase] = 1",
      "mutated_line": "phrase_dict[phrase] = 0",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 0\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "phrase_dict[phrase] = 1",
      "mutated_line": "phrase_dict[phrase] = 0",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 0\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "CRP",
      "lineno": 27,
      "original_line": "phrase_dict[phrase] = 1",
      "mutated_line": "phrase_dict[phrase] = -1",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = -1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ROR",
      "lineno": 53,
      "original_line": "if neighbor not in visited:",
      "mutated_line": "if neighbor in visited:",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    },
    {
      "operator": "ROR",
      "lineno": 39,
      "original_line": "if any(word in other_phrase for word in phrase):",
      "mutated_line": "if any((word not in other_phrase for word in phrase)):",
      "code": "def ToPMine(documents):\n    \"\"\"\n    Mine topics and phrases in large documents.\n\n    Parameters:\n    documents (list): A list of strings representing the documents to be mined.\n\n    Returns:\n    topics (list): A list of topics extracted from the documents.\n    \"\"\"\n    tokens = [document.split() for document in documents]\n    stop_words = set(['is', 'the', 'and', 'a', 'an', 'in', 'on', 'at', 'by', 'with'])\n    filtered_tokens = [[word for word in token if word.lower() not in stop_words] for token in tokens]\n    phrase_dict = {}\n    for token in filtered_tokens:\n        for i in range(len(token)):\n            for j in range(i + 1, len(token) + 1):\n                phrase = tuple(token[i:j])\n                if phrase in phrase_dict:\n                    phrase_dict[phrase] += 1\n                else:\n                    phrase_dict[phrase] = 1\n    threshold = 5\n    filtered_phrases = {phrase: count for (phrase, count) in phrase_dict.items() if count >= threshold}\n    graph = {}\n    for phrase in filtered_phrases:\n        graph[phrase] = []\n        for other_phrase in filtered_phrases:\n            if phrase != other_phrase:\n                if any((word not in other_phrase for word in phrase)):\n                    graph[phrase].append(other_phrase)\n    topics = []\n    visited = set()\n    for phrase in graph:\n        if phrase not in visited:\n            cluster = [phrase]\n            stack = [phrase]\n            while stack:\n                node = stack.pop()\n                visited.add(node)\n                for neighbor in graph[node]:\n                    if neighbor not in visited:\n                        cluster.append(neighbor)\n                        stack.append(neighbor)\n            topics.append(cluster)\n    return topics"
    }
  ]
}