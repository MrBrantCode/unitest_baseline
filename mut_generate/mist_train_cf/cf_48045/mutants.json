{
  "task_id": "cf_48045",
  "entry_point": "compare_docs",
  "mutant_count": 5,
  "mutants": [
    {
      "operator": "AOR",
      "lineno": 10,
      "original_line": "common_words = set(doc1_words.keys()) & set(doc2_words.keys())",
      "mutated_line": "return (len(common_words), {word: (doc1_words[word], doc2_words[word]) for word in common_words})",
      "code": "import collections\nimport string\n\ndef compare_docs(doc1, doc2):\n    doc1_words = collections.Counter(doc1.translate(str.maketrans('', '', string.punctuation)).lower().split())\n    doc2_words = collections.Counter(doc2.translate(str.maketrans('', '', string.punctuation)).lower().split())\n    common_words = set(doc1_words.keys()) | set(doc2_words.keys())\n    return (len(common_words), {word: (doc1_words[word], doc2_words[word]) for word in common_words})"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "doc1_words = collections.Counter(doc1.translate(str.maketrans('', '', string.punctuation)).lower().split())",
      "mutated_line": "doc1_words = collections.Counter(doc1.translate(str.maketrans('MUTATED', '', string.punctuation)).lower().split())",
      "code": "import collections\nimport string\n\ndef compare_docs(doc1, doc2):\n    doc1_words = collections.Counter(doc1.translate(str.maketrans('MUTATED', '', string.punctuation)).lower().split())\n    doc2_words = collections.Counter(doc2.translate(str.maketrans('', '', string.punctuation)).lower().split())\n    common_words = set(doc1_words.keys()) & set(doc2_words.keys())\n    return (len(common_words), {word: (doc1_words[word], doc2_words[word]) for word in common_words})"
    },
    {
      "operator": "CRP",
      "lineno": 6,
      "original_line": "doc1_words = collections.Counter(doc1.translate(str.maketrans('', '', string.punctuation)).lower().split())",
      "mutated_line": "doc1_words = collections.Counter(doc1.translate(str.maketrans('', 'MUTATED', string.punctuation)).lower().split())",
      "code": "import collections\nimport string\n\ndef compare_docs(doc1, doc2):\n    doc1_words = collections.Counter(doc1.translate(str.maketrans('', 'MUTATED', string.punctuation)).lower().split())\n    doc2_words = collections.Counter(doc2.translate(str.maketrans('', '', string.punctuation)).lower().split())\n    common_words = set(doc1_words.keys()) & set(doc2_words.keys())\n    return (len(common_words), {word: (doc1_words[word], doc2_words[word]) for word in common_words})"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "doc2_words = collections.Counter(doc2.translate(str.maketrans('', '', string.punctuation)).lower().split())",
      "mutated_line": "doc2_words = collections.Counter(doc2.translate(str.maketrans('MUTATED', '', string.punctuation)).lower().split())",
      "code": "import collections\nimport string\n\ndef compare_docs(doc1, doc2):\n    doc1_words = collections.Counter(doc1.translate(str.maketrans('', '', string.punctuation)).lower().split())\n    doc2_words = collections.Counter(doc2.translate(str.maketrans('MUTATED', '', string.punctuation)).lower().split())\n    common_words = set(doc1_words.keys()) & set(doc2_words.keys())\n    return (len(common_words), {word: (doc1_words[word], doc2_words[word]) for word in common_words})"
    },
    {
      "operator": "CRP",
      "lineno": 7,
      "original_line": "doc2_words = collections.Counter(doc2.translate(str.maketrans('', '', string.punctuation)).lower().split())",
      "mutated_line": "doc2_words = collections.Counter(doc2.translate(str.maketrans('', 'MUTATED', string.punctuation)).lower().split())",
      "code": "import collections\nimport string\n\ndef compare_docs(doc1, doc2):\n    doc1_words = collections.Counter(doc1.translate(str.maketrans('', '', string.punctuation)).lower().split())\n    doc2_words = collections.Counter(doc2.translate(str.maketrans('', 'MUTATED', string.punctuation)).lower().split())\n    common_words = set(doc1_words.keys()) & set(doc2_words.keys())\n    return (len(common_words), {word: (doc1_words[word], doc2_words[word]) for word in common_words})"
    }
  ]
}